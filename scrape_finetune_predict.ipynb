{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scrape arxiv and save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxivscraper as ax\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "scraper = ax.Scraper(category='stat', date_from='2017-08-01',\n",
    "                     date_until='2019-07-01', t=10, \n",
    "                     filters={'categories':['stat.ml'],'abstract':['learning']})\n",
    "'''\n",
    "scraper = ax.Scraper(category='q-bio', date_from='2016-08-01',\n",
    "                     date_until='2019-07-01', t=10, \n",
    "                     filters={'categories':['q-bio.GN', 'q-bio.NC']})\n",
    "output = scraper.scrape()\n",
    "\n",
    "\n",
    "# cols = ('id', 'title', 'categories', 'abstract', 'doi', 'created', 'updated', 'authors')\n",
    "titles = [' '.join(o['title'].split()) for o in output]\n",
    "\n",
    "np.savetxt('titles.csv', np.array(titles), fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finetune gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interrupted\n",
      "Saving checkpoint/run1/model-105\n",
      "<|startoftext|>how the brain learns to interpret visual stimuli correctly<|endoftext|>\n",
      "<|startoftext|>a new sequencing approach for phylogenetic tree of lupus erythematos (sydney) cancer<|endoftext|>\n",
      "<|startoftext|>a review of the current state of knowledge in the field of neural engineering<|endoftext|>\n",
      "<|startoftext|>a more complete description of the neural code for bifidobacterium histracis than of lupus<|endoftext|>\n",
      "<|startoftext|>how the brain relates to a smartphone: public perception and control<|endoftext|>\n",
      "<|startoftext|>small deviations error correction of the neural code and big leaps error correction of the neural spike-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing-timing\n"
     ]
    }
   ],
   "source": [
    "import gpt_2_simple as gpt2\n",
    "\n",
    "model_name = \"117M\"\n",
    "gpt2.download_gpt2(model_name=model_name)   # model is saved into current directory under /models/117M/\n",
    "\n",
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.finetune(sess,\n",
    "              'titles.csv',\n",
    "              model_name=model_name,\n",
    "              steps=601,\n",
    "              save_every=200,\n",
    "              sample_every=25)   # steps is max number of training steps\n",
    "\n",
    "gpt2.generate(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = 'samples/samples-901'\n",
    "t = open(sample_file, 'r').read()\n",
    "\n",
    "for s in ['endoftext', 'startoftext', '<|', '|>']:\n",
    "    t = t.replace(s, '')\n",
    "for title in t.title().split('\\n')[1:]:\n",
    "    if not title == '':\n",
    "        print('- ' + title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0801 04:51:30.227832 140240784951104 deprecation.py:323] From /system/linux/anaconda3.7/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint checkpoint/run1/model-1000\n"
     ]
    }
   ],
   "source": [
    "import gpt_2_simple as gpt2\n",
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Source Separation Via Non-Negative Eigenvector Field Variate Operator\n"
     ]
    }
   ],
   "source": [
    "prefix = 'neural' # None is default\n",
    "text = gpt2.generate(sess,\n",
    "              length=40,\n",
    "              temperature=0.7,\n",
    "              prefix=neural,\n",
    "              nsamples=1,\n",
    "              batch_size=1,\n",
    "              return_as_list=True\n",
    "             )\n",
    "\n",
    "\n",
    "t = text[0].title()\n",
    "t = t.replace('<|Startoftext|>', '').replace('\\n', '') # remove extraneous stuff\n",
    "t = t[:t.index('<|Endoftext|>')] # only get one title\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**bunch of samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = gpt2.generate(sess,\n",
    "#               length=40,\n",
    "              temperature=0.7,\n",
    "              prefix=None,\n",
    "              nsamples=100,\n",
    "              batch_size=1,\n",
    "              return_as_list=True\n",
    "             )\n",
    "\n",
    "\n",
    "t = text[0].title()\n",
    "t = t.replace('<|Startoftext|>', '').replace('\\n', '') # remove extraneous stuff\n",
    "t = t[:t.index('<|Endoftext|>')] # only get one title\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
